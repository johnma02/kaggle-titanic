{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jonathanma02/titanic-dataset?scriptVersionId=101187514\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# finding data set locale\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-18T23:13:46.891471Z","iopub.execute_input":"2022-07-18T23:13:46.892105Z","iopub.status.idle":"2022-07-18T23:13:46.90096Z","shell.execute_reply.started":"2022-07-18T23:13:46.892066Z","shell.execute_reply":"2022-07-18T23:13:46.90005Z"},"trusted":true},"execution_count":805,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ncombined = [train_df, test_df] ","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:46.946803Z","iopub.execute_input":"2022-07-18T23:13:46.947118Z","iopub.status.idle":"2022-07-18T23:13:46.961636Z","shell.execute_reply.started":"2022-07-18T23:13:46.947087Z","shell.execute_reply":"2022-07-18T23:13:46.960763Z"},"trusted":true},"execution_count":806,"outputs":[]},{"cell_type":"markdown","source":"### Deep Neural Network Implementation for Predicting Titanic Passenger Survivorship\n#### Written by Jonathan Ma - 06/17/2022","metadata":{}},{"cell_type":"markdown","source":"Welcome to my data analysis and modeling notebook for predicting survivorship of passengers on the Titanic. Briefly, let's discuss some important facts about the Titanic.\n\n- The Titanic was a British passenger liner which struck an iceberg on April 15, 1912, and sunk to the ocean floor. \n- Aboard the Titanic were lifeboats with an estimated capacity of 1,178 people — massively insufficient for the estimated 2,224 passengers and crew aboard.\n- When deciding who should be given priority for boarding the lifeboats, **women and infants were given priority.**\n- Tickets for the Titanic's maiden voyage were stratified into three classes: **first, second, and third class, with increasing corresponding price.**\n\n#### Let's begin by previewing our data, and defining our variables.","metadata":{}},{"cell_type":"code","source":"train_df.tail(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:47.05129Z","iopub.execute_input":"2022-07-18T23:13:47.051919Z","iopub.status.idle":"2022-07-18T23:13:47.068326Z","shell.execute_reply.started":"2022-07-18T23:13:47.051884Z","shell.execute_reply":"2022-07-18T23:13:47.06731Z"},"trusted":true},"execution_count":807,"outputs":[{"execution_count":807,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived  Pclass                                      Name  \\\n886          887         0       2                     Montvila, Rev. Juozas   \n887          888         1       1              Graham, Miss. Margaret Edith   \n888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n889          890         1       1                     Behr, Mr. Karl Howell   \n890          891         0       3                       Dooley, Mr. Patrick   \n\n        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n886    male  27.0      0      0      211536  13.00   NaN        S  \n887  female  19.0      0      0      112053  30.00   B42        S  \n888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n889    male  26.0      0      0      111369  30.00  C148        C  \n890    male  32.0      0      0      370376   7.75   NaN        Q  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.00</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.00</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.45</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.00</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.75</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Dictionary\n| Variable | Definition | Key |\n| --- | --- | --- |\n| survival | Survival | 0 = No, 1 = Yes |\n| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n| sex | Sex |  |\n| Age | Age in years |  |\n| sibsp | # of siblings / spouses aboard the Titanic |  |\n| parch | # of parents / children aboard the Titanic |  |\n| ticket | Ticket number |  | \n| fare | Passenger fare |  |\n| cabin | Cabin number |  |\n| embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |\n\n\n# Classifying Data\nWe will begin our data analysis by classifying our variables\n#### Categorical Data\n- Ordinal Data: pclass\n- Nominal Data: embarked, survived, sex, name\n\n\n#### Numerical Data\n- Discrete Data: age, sibsp, parch\n- Continuous Data: fare\n\n\n#### Mixed Data\n- cabin: Latin letter followed by a number\n- ticket: Mix of numbers and Latin strings followed by numbers\n\nNow that we have an idea of what our variables mean, let's move on to identifying the state of our dataset.\n    ","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:47.1344Z","iopub.execute_input":"2022-07-18T23:13:47.135086Z","iopub.status.idle":"2022-07-18T23:13:47.166364Z","shell.execute_reply.started":"2022-07-18T23:13:47.135054Z","shell.execute_reply":"2022-07-18T23:13:47.16527Z"},"trusted":true},"execution_count":808,"outputs":[{"execution_count":808,"output_type":"execute_result","data":{"text/plain":"       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.describe(include='O')","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:47.203518Z","iopub.execute_input":"2022-07-18T23:13:47.203787Z","iopub.status.idle":"2022-07-18T23:13:47.225316Z","shell.execute_reply.started":"2022-07-18T23:13:47.203762Z","shell.execute_reply":"2022-07-18T23:13:47.224473Z"},"trusted":true},"execution_count":809,"outputs":[{"execution_count":809,"output_type":"execute_result","data":{"text/plain":"                           Name   Sex  Ticket    Cabin Embarked\ncount                       891   891     891      204      889\nunique                      891     2     681      147        3\ntop     Braund, Mr. Owen Harris  male  347082  B96 B98        S\nfreq                          1   577       7        4      644","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Ticket</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891</td>\n      <td>891</td>\n      <td>891</td>\n      <td>204</td>\n      <td>889</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>891</td>\n      <td>2</td>\n      <td>681</td>\n      <td>147</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>347082</td>\n      <td>B96 B98</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>577</td>\n      <td>7</td>\n      <td>4</td>\n      <td>644</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Looks like we are missing some age and embarkement location labels. Additionally, it looks like our cabin number variable is unusable — we are missing too many values. We will deal with these null values when we clean our data, but for now, let's find some correlations in our data.","metadata":{}},{"cell_type":"markdown","source":"### Analysis","metadata":{}},{"cell_type":"markdown","source":"We can posit that a higher passenger class led to higher survival rates.","metadata":{}},{"cell_type":"code","source":"train_df[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index=False).mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:47.271723Z","iopub.execute_input":"2022-07-18T23:13:47.272058Z","iopub.status.idle":"2022-07-18T23:13:47.287426Z","shell.execute_reply.started":"2022-07-18T23:13:47.272029Z","shell.execute_reply":"2022-07-18T23:13:47.286319Z"},"trusted":true},"execution_count":810,"outputs":[{"execution_count":810,"output_type":"execute_result","data":{"text/plain":"   Pclass  Survived\n0       1  0.629630\n1       2  0.472826\n2       3  0.242363","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.629630</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.472826</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.242363</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"And of course, females were more likely to survive the sinking, being given priority boarding to the lifeboats.","metadata":{}},{"cell_type":"code","source":"train_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index=False).mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:47.339298Z","iopub.execute_input":"2022-07-18T23:13:47.339641Z","iopub.status.idle":"2022-07-18T23:13:47.354652Z","shell.execute_reply.started":"2022-07-18T23:13:47.339611Z","shell.execute_reply":"2022-07-18T23:13:47.353231Z"},"trusted":true},"execution_count":811,"outputs":[{"execution_count":811,"output_type":"execute_result","data":{"text/plain":"      Sex  Survived\n0  female  0.742038\n1    male  0.188908","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>female</td>\n      <td>0.742038</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>male</td>\n      <td>0.188908</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's see if ticket fare played a role in survival rate by using a histogram to visualize our data.","metadata":{}},{"cell_type":"code","source":"fare_histogram = sns.FacetGrid(train_df, col = \"Survived\")\nfare_histogram.map(plt.hist, \"Fare\", bins=25)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:47.404229Z","iopub.execute_input":"2022-07-18T23:13:47.404778Z","iopub.status.idle":"2022-07-18T23:13:47.83323Z","shell.execute_reply.started":"2022-07-18T23:13:47.404747Z","shell.execute_reply":"2022-07-18T23:13:47.832317Z"},"trusted":true},"execution_count":812,"outputs":[{"execution_count":812,"output_type":"execute_result","data":{"text/plain":"<seaborn.axisgrid.FacetGrid at 0x7fafa4d58850>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x216 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"We can do the same with passenger age.","metadata":{}},{"cell_type":"code","source":"age_histogram = sns.FacetGrid(train_df, col = \"Survived\")\nage_histogram.map(plt.hist, \"Age\", bins = 20)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:47.8356Z","iopub.execute_input":"2022-07-18T23:13:47.836326Z","iopub.status.idle":"2022-07-18T23:13:48.238721Z","shell.execute_reply.started":"2022-07-18T23:13:47.836285Z","shell.execute_reply":"2022-07-18T23:13:48.237831Z"},"trusted":true},"execution_count":813,"outputs":[{"execution_count":813,"output_type":"execute_result","data":{"text/plain":"<seaborn.axisgrid.FacetGrid at 0x7fafa491df50>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x216 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"Finally, as port of embarkment reveal geographical differences of wealth, we can assume that it may also have had a direct impact on survival rate.","metadata":{}},{"cell_type":"code","source":"train_df[[\"Embarked\", \"Survived\"]].groupby([\"Embarked\"], as_index=False).mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.240029Z","iopub.execute_input":"2022-07-18T23:13:48.240458Z","iopub.status.idle":"2022-07-18T23:13:48.257533Z","shell.execute_reply.started":"2022-07-18T23:13:48.240419Z","shell.execute_reply":"2022-07-18T23:13:48.25673Z"},"trusted":true},"execution_count":814,"outputs":[{"execution_count":814,"output_type":"execute_result","data":{"text/plain":"  Embarked  Survived\n0        C  0.553571\n1        Q  0.389610\n2        S  0.336957","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Embarked</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C</td>\n      <td>0.553571</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q</td>\n      <td>0.389610</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>S</td>\n      <td>0.336957</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"With our preliminary data analysis, we have that:\n\n\n- Gender played a vital role in survivorship in the Titanic (74% of females survived vs. ~19% of males)\n- Passenger class also heavily affected survivorship (63% of First class passengers survived vs. 24% in Third class)\n- A lower fare points towards to a lower survival rate.\n- Infants in particular had a greater chance of survival on the Titanic.\n- Port of embarkment affected survivorship.\n\nLet's work on condensing our variables into usable features for our model.\n","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering\n\n### Titles\nDuring the early 20th century, certain titles were a rare commodity amongst commmon folk. Typically, titles such as Dr. or Sir. were reserved for higher class members of society. We will take advantage of the fact that our data set contains titles, and create a new input feature named \"Title.\" Luckily, this will only involve some quick globbing, as the titles all end with periods.","metadata":{}},{"cell_type":"code","source":"for i in combined:\n    i[\"Title\"] = i[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\npd.crosstab(train_df[\"Title\"], train_df[\"Sex\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.260111Z","iopub.execute_input":"2022-07-18T23:13:48.260599Z","iopub.status.idle":"2022-07-18T23:13:48.284251Z","shell.execute_reply.started":"2022-07-18T23:13:48.260563Z","shell.execute_reply":"2022-07-18T23:13:48.283375Z"},"trusted":true},"execution_count":815,"outputs":[{"execution_count":815,"output_type":"execute_result","data":{"text/plain":"Sex       female  male\nTitle                 \nCapt           0     1\nCol            0     2\nCountess       1     0\nDon            0     1\nDr             1     6\nJonkheer       0     1\nLady           1     0\nMajor          0     2\nMaster         0    40\nMiss         182     0\nMlle           2     0\nMme            1     0\nMr             0   517\nMrs          125     0\nMs             1     0\nRev            0     6\nSir            0     1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Sex</th>\n      <th>female</th>\n      <th>male</th>\n    </tr>\n    <tr>\n      <th>Title</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Capt</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Col</th>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Countess</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Don</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Dr</th>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>Jonkheer</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Lady</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Major</th>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Master</th>\n      <td>0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>Miss</th>\n      <td>182</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Mlle</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Mme</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Mr</th>\n      <td>0</td>\n      <td>517</td>\n    </tr>\n    <tr>\n      <th>Mrs</th>\n      <td>125</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Ms</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Rev</th>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>Sir</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We can immediately see that the majority of these titles fall under commoner titles (Miss., Mr., Mrs., etc.), and we have a good number of ~~Jedi~~ \"Masters\" aboard the Titanic. We will go ahead and group together the rarer titles in a category called \"Exotic\". We will also clean up the data by anglicizing the titles.","metadata":{}},{"cell_type":"code","source":"for i in combined:\n    i[\"Title\"] = i[\"Title\"].replace([\"Lady\", \"Countess\", \"Capt\", \"Col\",\n                                     \"Don\", \"Dr\", \"Major\", \"Rev\", \"Sir\",\n                                     \"Jonkheer\", \"Dona\"], \"Exotic\")\n    i[\"Title\"] = i[\"Title\"].replace(\"Mlle\", \"Miss\")\n    i[\"Title\"] = i[\"Title\"].replace(\"Ms\", \"Miss\")\n    i[\"Title\"] = i[\"Title\"].replace(\"Mme\", \"Mrs\")\n    \ntrain_df[[\"Title\", \"Survived\"]].groupby([\"Title\"], as_index=False).mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.285583Z","iopub.execute_input":"2022-07-18T23:13:48.285917Z","iopub.status.idle":"2022-07-18T23:13:48.308609Z","shell.execute_reply.started":"2022-07-18T23:13:48.285883Z","shell.execute_reply":"2022-07-18T23:13:48.30756Z"},"trusted":true},"execution_count":816,"outputs":[{"execution_count":816,"output_type":"execute_result","data":{"text/plain":"    Title  Survived\n0  Exotic  0.347826\n1  Master  0.575000\n2    Miss  0.702703\n3      Mr  0.156673\n4     Mrs  0.793651","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Exotic</td>\n      <td>0.347826</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Master</td>\n      <td>0.575000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Miss</td>\n      <td>0.702703</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Mr</td>\n      <td>0.156673</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mrs</td>\n      <td>0.793651</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"As expected, the feminine titles had higher survival rates, and the more \"High Society\" titles had higher survival rates than commoner titles. We will convert these categorical titles to ordinal titles by survival rate.","metadata":{}},{"cell_type":"code","source":"title_map = {\"Mr\": 1, \"Exotic\": 2, \"Master\": 3, \"Miss\": 4, \"Mrs\": 5}\nfor i in combined:\n    i[\"Title\"] = i[\"Title\"].map(title_map)\n    i[\"Title\"] = i[\"Title\"].fillna(0)\ntrain_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.310035Z","iopub.execute_input":"2022-07-18T23:13:48.310376Z","iopub.status.idle":"2022-07-18T23:13:48.329496Z","shell.execute_reply.started":"2022-07-18T23:13:48.310341Z","shell.execute_reply":"2022-07-18T23:13:48.328627Z"},"trusted":true},"execution_count":817,"outputs":[{"execution_count":817,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived  Pclass                                      Name  \\\n886          887         0       2                     Montvila, Rev. Juozas   \n887          888         1       1              Graham, Miss. Margaret Edith   \n888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n889          890         1       1                     Behr, Mr. Karl Howell   \n890          891         0       3                       Dooley, Mr. Patrick   \n\n        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  Title  \n886    male  27.0      0      0      211536  13.00   NaN        S      2  \n887  female  19.0      0      0      112053  30.00   B42        S      4  \n888  female   NaN      1      2  W./C. 6607  23.45   NaN        S      4  \n889    male  26.0      0      0      111369  30.00  C148        C      1  \n890    male  32.0      0      0      370376   7.75   NaN        Q      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.00</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.00</td>\n      <td>B42</td>\n      <td>S</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.45</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.00</td>\n      <td>C148</td>\n      <td>C</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.75</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The data looks a little unwieldy right now, so let's drop some unneeded variables. We don't need name anymore, as we've extracted the only meaningful part of the variable. As stated previously, Cabin number is utterly incomplete, so we will drop that variable. Ticket number should not contribute meaningfully to our model, as it's a unique identifier. Finally, passenger ID is used purely for submission purposes, so let's drop that for now.","metadata":{}},{"cell_type":"code","source":"train_df = train_df.drop([\"Name\", \"PassengerId\", \"Ticket\", \"Cabin\"], axis=1)\ntest_df = test_df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1)\ncombined = [train_df, test_df]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.331027Z","iopub.execute_input":"2022-07-18T23:13:48.331445Z","iopub.status.idle":"2022-07-18T23:13:48.352129Z","shell.execute_reply.started":"2022-07-18T23:13:48.331409Z","shell.execute_reply":"2022-07-18T23:13:48.35147Z"},"trusted":true},"execution_count":818,"outputs":[{"execution_count":818,"output_type":"execute_result","data":{"text/plain":"   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  Title\n0         0       3    male  22.0      1      0   7.2500        S      1\n1         1       1  female  38.0      1      0  71.2833        C      5\n2         1       3  female  26.0      0      0   7.9250        S      4\n3         1       1  female  35.0      1      0  53.1000        S      5\n4         0       3    male  35.0      0      0   8.0500        S      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Much better. Let's also map Sex onto a boolean function of Female or not Female.","metadata":{}},{"cell_type":"code","source":"for i in combined:\n    i[\"Sex\"] = i[\"Sex\"].map({\"female\": 1, \"male\":0}).astype('int')\n    \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.353062Z","iopub.execute_input":"2022-07-18T23:13:48.353306Z","iopub.status.idle":"2022-07-18T23:13:48.372671Z","shell.execute_reply.started":"2022-07-18T23:13:48.353283Z","shell.execute_reply":"2022-07-18T23:13:48.371848Z"},"trusted":true},"execution_count":819,"outputs":[{"execution_count":819,"output_type":"execute_result","data":{"text/plain":"   Survived  Pclass  Sex   Age  SibSp  Parch     Fare Embarked  Title\n0         0       3    0  22.0      1      0   7.2500        S      1\n1         1       1    1  38.0      1      0  71.2833        C      5\n2         1       3    1  26.0      0      0   7.9250        S      4\n3         1       1    1  35.0      1      0  53.1000        S      5\n4         0       3    0  35.0      0      0   8.0500        S      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Completing Null Entries\nEarlier, we noticed that some of the Age values are missing. Let's generate some random numbers between the mean and the standard deviation to quickly fill those missing entries.","metadata":{}},{"cell_type":"code","source":"age_mean = int(train_df[\"Age\"].mean())\nage_std = int(train_df[\"Age\"].std())\n\nfor i in combined:\n    i.loc[i.Age.isnull(), 'Age'] = np.random.randint(\n        age_std, age_mean)\n    i[\"Age\"] = i[\"Age\"].astype('int')\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.373863Z","iopub.execute_input":"2022-07-18T23:13:48.374287Z","iopub.status.idle":"2022-07-18T23:13:48.393833Z","shell.execute_reply.started":"2022-07-18T23:13:48.374248Z","shell.execute_reply":"2022-07-18T23:13:48.393137Z"},"trusted":true},"execution_count":820,"outputs":[{"execution_count":820,"output_type":"execute_result","data":{"text/plain":"   Survived  Pclass  Sex  Age  SibSp  Parch     Fare Embarked  Title\n0         0       3    0   22      1      0   7.2500        S      1\n1         1       1    1   38      1      0  71.2833        C      5\n2         1       3    1   26      0      0   7.9250        S      4\n3         1       1    1   35      1      0  53.1000        S      5\n4         0       3    0   35      0      0   8.0500        S      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>22</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>38</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>26</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>35</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Onto our Sibling/Spouse count and Parents/Children count variables. These variables are a mess. Let's condense them into one variable: family size. Then, let's see if we can spot some correlation between family size and survival rate.","metadata":{}},{"cell_type":"code","source":"for i in combined:\n    i[\"FamilySize\"] = i[\"SibSp\"] + i[\"Parch\"] + 1\n\ntrain_df[[\"FamilySize\", \"Survived\"]].groupby([\"FamilySize\"], as_index=False).mean().sort_values(by=\"Survived\", ascending=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.396235Z","iopub.execute_input":"2022-07-18T23:13:48.397065Z","iopub.status.idle":"2022-07-18T23:13:48.413806Z","shell.execute_reply.started":"2022-07-18T23:13:48.397032Z","shell.execute_reply":"2022-07-18T23:13:48.412856Z"},"trusted":true},"execution_count":821,"outputs":[{"execution_count":821,"output_type":"execute_result","data":{"text/plain":"   FamilySize  Survived\n7           8  0.000000\n8          11  0.000000\n5           6  0.136364\n4           5  0.200000\n0           1  0.303538\n6           7  0.333333\n1           2  0.552795\n2           3  0.578431\n3           4  0.724138","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FamilySize</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>11</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.136364</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.200000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.303538</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.552795</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.578431</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.724138</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"It looks like generally there is little correlation between survivorship and family size. Let's dig a little deeper and see if there is correlation between passengers who were alone and passengers who boarded the Titanic with a family.","metadata":{}},{"cell_type":"code","source":"for i in combined:\n    i[\"Alone\"] = 0\n    i.loc[i[\"FamilySize\"] == 1, \"Alone\"] = 1\n\ntrain_df[[\"Alone\", \"Survived\"]].groupby([\"Alone\"], as_index=False).mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.415213Z","iopub.execute_input":"2022-07-18T23:13:48.415626Z","iopub.status.idle":"2022-07-18T23:13:48.433007Z","shell.execute_reply.started":"2022-07-18T23:13:48.415589Z","shell.execute_reply":"2022-07-18T23:13:48.432176Z"},"trusted":true},"execution_count":822,"outputs":[{"execution_count":822,"output_type":"execute_result","data":{"text/plain":"   Alone  Survived\n0      0  0.505650\n1      1  0.303538","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alone</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.505650</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.303538</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Here, we can see that there is some correlation between boarding the Titanic independently and survival. We will keep this final feature and drop the Sibling Count and Parent Count variables.","metadata":{}},{"cell_type":"code","source":"train_df = train_df.drop([\"Parch\", \"SibSp\", \"FamilySize\"], axis=1)\ntest_df = test_df.drop([\"Parch\", \"SibSp\", \"FamilySize\"], axis=1)\ncombined = [train_df, test_df]\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.43431Z","iopub.execute_input":"2022-07-18T23:13:48.434677Z","iopub.status.idle":"2022-07-18T23:13:48.452807Z","shell.execute_reply.started":"2022-07-18T23:13:48.434641Z","shell.execute_reply":"2022-07-18T23:13:48.452125Z"},"trusted":true},"execution_count":823,"outputs":[{"execution_count":823,"output_type":"execute_result","data":{"text/plain":"   Survived  Pclass  Sex  Age     Fare Embarked  Title  Alone\n0         0       3    0   22   7.2500        S      1      0\n1         1       1    1   38  71.2833        C      5      0\n2         1       3    1   26   7.9250        S      4      1\n3         1       1    1   35  53.1000        S      5      0\n4         0       3    0   35   8.0500        S      1      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Title</th>\n      <th>Alone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>22</td>\n      <td>7.2500</td>\n      <td>S</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>38</td>\n      <td>71.2833</td>\n      <td>C</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>26</td>\n      <td>7.9250</td>\n      <td>S</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35</td>\n      <td>53.1000</td>\n      <td>S</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>35</td>\n      <td>8.0500</td>\n      <td>S</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Finally, let's sort embarkment ports by survival rate, and refactor Embarked as ordinal data. In this step, we will also complete our dataset by replacing the two missing embarkment entries with the most common embarkment point.","metadata":{}},{"cell_type":"code","source":"for i in combined:\n    i[\"Embarked\"] = i[\"Embarked\"].fillna(train_df.Embarked.dropna().mode()[0])\ntrain_df[[\"Embarked\", \"Survived\"]].groupby([\"Embarked\"], as_index=False).mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.453875Z","iopub.execute_input":"2022-07-18T23:13:48.454295Z","iopub.status.idle":"2022-07-18T23:13:48.471849Z","shell.execute_reply.started":"2022-07-18T23:13:48.454259Z","shell.execute_reply":"2022-07-18T23:13:48.471151Z"},"trusted":true},"execution_count":824,"outputs":[{"execution_count":824,"output_type":"execute_result","data":{"text/plain":"  Embarked  Survived\n0        C  0.553571\n1        Q  0.389610\n2        S  0.339009","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Embarked</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C</td>\n      <td>0.553571</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q</td>\n      <td>0.389610</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>S</td>\n      <td>0.339009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for i in combined:\n    i[\"Embarked\"] = i[\"Embarked\"].map({\"S\": 0, \"Q\": 1, \"C\": 2}).astype('int')\ntrain_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.473023Z","iopub.execute_input":"2022-07-18T23:13:48.473538Z","iopub.status.idle":"2022-07-18T23:13:48.491181Z","shell.execute_reply.started":"2022-07-18T23:13:48.473497Z","shell.execute_reply":"2022-07-18T23:13:48.490375Z"},"trusted":true},"execution_count":825,"outputs":[{"execution_count":825,"output_type":"execute_result","data":{"text/plain":"   Survived  Pclass  Sex  Age     Fare  Embarked  Title  Alone\n0         0       3    0   22   7.2500         0      1      0\n1         1       1    1   38  71.2833         2      5      0\n2         1       3    1   26   7.9250         0      4      1\n3         1       1    1   35  53.1000         0      5      0\n4         0       3    0   35   8.0500         0      1      1\n5         0       3    0   17   8.4583         1      1      1\n6         0       1    0   54  51.8625         0      1      1\n7         0       3    0    2  21.0750         0      3      0\n8         1       3    1   27  11.1333         0      5      0\n9         1       2    1   14  30.0708         2      5      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Title</th>\n      <th>Alone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>22</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>38</td>\n      <td>71.2833</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>26</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>35</td>\n      <td>53.1000</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>35</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>17</td>\n      <td>8.4583</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>54</td>\n      <td>51.8625</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>21.0750</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>27</td>\n      <td>11.1333</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>14</td>\n      <td>30.0708</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Finally, this is how our cleaned data set looks like.\n\n# L-Layer Neural Network\nNow that we're done with feature engineering, we can construct our neural network. We're going to do this from scratch using Numpy.\n\n### ReLU, Sigmoid Functions\nBecause we are doing a simple binary classification, we will be using the ReLU and Sigmoid functions as our activation functions. ","metadata":{}},{"cell_type":"code","source":"def sigmoid(Z: np.ndarray):\n    return 1/(1+np.exp(-Z)), Z\ndef relu(Z: np.ndarray):\n    return np.maximum(0, Z), Z\n\n# Our activation helper functions also return a cache value we will use for backpropagation","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.492387Z","iopub.execute_input":"2022-07-18T23:13:48.492748Z","iopub.status.idle":"2022-07-18T23:13:48.498558Z","shell.execute_reply.started":"2022-07-18T23:13:48.492713Z","shell.execute_reply":"2022-07-18T23:13:48.497739Z"},"trusted":true},"execution_count":826,"outputs":[]},{"cell_type":"markdown","source":"### Forward Propagation\nLet's write a few helper function to facilitate forward propagation.","metadata":{}},{"cell_type":"code","source":"def linear_forward(A, W, b):\n    \"\"\"\n    Implements linear part of a layer's forward propagation\n    Args:\n    A: Activations from previous layer\n    W: Weight matrices\n    b: bias vector\n    Returns:\n    Z: input of the activation function -- pre-activation parameter\n    cache -- used for backward propagation\n    \"\"\"\n\n    Z = np.dot(W,A)+b\n    cache = (A,W,b)\n    return Z, cache\n\ndef linear_activation_forward(A_prev, W, b, activation: str):\n    \"\"\"\n    Implements forward propagation for the linear->activation layer\n    Args:\n    A_prev: Activations from previous layer\n    W: Weight matrices\n    b: bias vector\n    activation: the activation function to be used in this layer, represented by a string\n    Returns:\n    A: output of the activation function -- post-activation value\n    cache -- used for backward propagation\n    \"\"\" \n    if activation == \"sigmoid\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = sigmoid(Z)\n    else:\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = relu(Z)\n    \n    cache = (linear_cache, activation_cache)\n    \n    return A, cache","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.500783Z","iopub.execute_input":"2022-07-18T23:13:48.501252Z","iopub.status.idle":"2022-07-18T23:13:48.510099Z","shell.execute_reply.started":"2022-07-18T23:13:48.501215Z","shell.execute_reply":"2022-07-18T23:13:48.509253Z"},"trusted":true},"execution_count":827,"outputs":[]},{"cell_type":"markdown","source":"With these functions written, we can write a function which implements forward propagation.","metadata":{}},{"cell_type":"code","source":"def nn_forward(X, parameters):\n    \"\"\"\n    Implements forward propagation for Linear->ReLU *(L-1) -> Linear-> Sigmoid computation\n    Args:\n    X: Input data\n    parameters: dictionary containing all the components necessary for forward propagation\n    Returns:\n    AL: Activation value from the output layer\n    caches: list of caches containing every cache of linear_activation_forward()\n    \"\"\"\n    caches = []\n    A = X\n    L = len(parameters)//2\n    \n    for i in range(1,L):\n        A_prev = A\n        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(i)], parameters[\"b\"+str(i)], \"relu\")\n        caches.append(cache)\n    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], \"sigmoid\")\n    caches.append(cache)\n    return AL, caches","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.526887Z","iopub.execute_input":"2022-07-18T23:13:48.527174Z","iopub.status.idle":"2022-07-18T23:13:48.535582Z","shell.execute_reply.started":"2022-07-18T23:13:48.527147Z","shell.execute_reply":"2022-07-18T23:13:48.534855Z"},"trusted":true},"execution_count":828,"outputs":[]},{"cell_type":"markdown","source":"### Cost Function\nLet's write a cost function: we will use this formula:\n$$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right))$$","metadata":{}},{"cell_type":"code","source":"def compute_cost(AL, Y):\n    \"\"\"\n    Computes cost of forward propagation.\n    Args:\n    AL: probability vector -- corresponds to label predictions\n    Y: label vector\n    Returns:\n    cost: vector containing computed cost values\n    \"\"\"\n    m = Y.shape[1]\n    cost = np.dot(-1/m, np.sum(np.multiply(np.log(AL+1e-7),Y) + np.multiply(np.log(1-AL+1e-7), 1-Y)))\n    cost = np.squeeze(cost)\n    return cost","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.588987Z","iopub.execute_input":"2022-07-18T23:13:48.589259Z","iopub.status.idle":"2022-07-18T23:13:48.595274Z","shell.execute_reply.started":"2022-07-18T23:13:48.589235Z","shell.execute_reply":"2022-07-18T23:13:48.594536Z"},"trusted":true},"execution_count":829,"outputs":[]},{"cell_type":"markdown","source":"### Backward Propagation\nWe're almost done with creating our neural network. Let's write some helper functions to tackle backward propagation. \n\nThe partial derivatives with respect to Z (weighted sum of the activations shifted by a bias) of the activation functions are as follows:\n\n\n### ReLU\n$$\n\\begin{equation}\n\\partial{J}{\\vec{Z}^{[l]}} = \\partial{J}{\\vec{A}^{[l]}} \\odot I(\\vec{Z}^{[l]} > 0),\n\\end{equation}$$\n\nwhere $\\odot$ denotes element-wise mulitplication.\n\n### Sigmoid\n$$\n\\begin{equation}\n\\partial{J}{\\vec{Z}^{[l]}} = \\partial{J}{\\vec{A}^{[l]}} \\odot \\vec{A}^{[l]} \\odot (1 - \\vec{A}^{[l]}).\n\\end{equation}\n$$\n\nWe will also be using the following formulas to write our backward propagation functions. \n$$ dW^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T}$$\n$$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}$$\n$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]}$$","metadata":{}},{"cell_type":"code","source":"def d_relu(dA, activation_cache):\n    Z = activation_cache\n    dZ = np.array(dA, copy=True) #converting dZ to the correct object\n    dZ[Z <= 0] = 0 #fixing negative values to 0\n    return dZ\n    \n\ndef d_sigmoid(dA, activation_cache):\n    Z = activation_cache\n    s, temp  = sigmoid(Z)\n    dZ = dA * s * (1-s)\n    return dZ\n\ndef linear_backward(dZ, cache):\n    \"\"\"\n    Linear portion of backward propagation for a single layer\n    Args:\n    dZ: Gradient of the cost with respect to the linear output\n    cache: tuple of values(A_prex, W, b) coming from the forward propagation in the current layer\n    Returns:\n    dA_prev: Gradient of the cost with respect to the activation of the previous layer (l-1)\n    dW: Gradient of the cost with respect to W in the current layer\n    db: Gradient of the cost with respect to b in the current layer\n    \"\"\"\n    A_prev, W, b = cache\n    m = A_prev.shape[1]\n    \n    dW = np.dot(1/m, np.dot(dZ, A_prev.T))\n    db = np.dot(1/m, np.sum(dZ, axis=1, keepdims=True))\n    dA_prev = np.dot(W.T, dZ)\n    \n    return dA_prev, dW, db\n\ndef linear_activation_backward(dA, cache, activation):\n    \"\"\"\n    Implements backward propagation for the Linear -> Activation layer\n    Args:\n    dA: post-activation gradient for current layer\n    cache: tuple of values(linear_cache, activation_cache)\n    activation: activation function to be used in this layer -- represented by a string\n    \n    Returns:\n    dA_prev: Gradient of the cost with respect to the activation of the previous layer\n    dW: Gradient of the cost with respect to W\n    db: Gradient of the cost with respect to b\n    \"\"\"\n    linear_cache, activation_cache = cache\n    \n    if activation == \"relu\":\n        dZ = d_relu(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    else:\n        dZ = d_sigmoid(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n        \n    return dA_prev, dW, db","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.656552Z","iopub.execute_input":"2022-07-18T23:13:48.657158Z","iopub.status.idle":"2022-07-18T23:13:48.668582Z","shell.execute_reply.started":"2022-07-18T23:13:48.657124Z","shell.execute_reply":"2022-07-18T23:13:48.667705Z"},"trusted":true},"execution_count":830,"outputs":[]},{"cell_type":"markdown","source":"With all the helper functions written, let's finally write our backpropagation function. We know our output equals $A^{[L]} = \\sigma(Z^{[L]})$. Through some calculus, we derive the partial derivative of the cost with respect to $A^{[L]}$, which is equal to\n\n$$\\begin{equation}\n\\frac{\\partial{J}}{\\partial\\vec{A}^{[L]}}= \\frac{1}{m} \\Bigl(\\frac{1}{1 - \\vec{A}^{[L]}} \\odot (1 - \\vec{Y}) - \\frac{1}{\\vec{A}^{[L]}} \\odot \\vec{Y}\\Bigr).\n\\end{equation}$$\n\n\nWe will use a for loop to iterate through all the layers of our neural network, storing dA, dW, and db in a dictionary.","metadata":{}},{"cell_type":"code","source":"def nn_backprop(AL, Y, caches):\n    \"\"\"\n    Implements backward propagation for Linear->ReLU * (L-1) -> Linear -> Sigmoid computation\n    Args:\n    AL: output of forward propagation\n    Y: label vectors\n    caches: list of caches containing every cache of linear_activation_forward() with \"relu\" and \"sigmoid\"\n    Returns:\n    grads: A dictionary with our computed gradients\n    \"\"\"\n    grads = {}\n    L = len(caches)\n    m = AL.shape[1]\n    Y = Y.reshape(AL.shape)\n    \n    dAL = -(np.divide(Y,AL+1e-7) - np.divide(1-Y, 1-AL+1e-7))\n    \n    current_cache = caches[L-1]\n    dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n    grads[\"dA\"+str(L-1)] = dA_prev_temp\n    grads[\"dW\"+str(L)] = dW_temp\n    grads[\"db\"+str(L)] = db_temp\n    \n    for i in reversed(range(L-1)):\n        current_cache = caches[i]\n        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dA_prev_temp, current_cache, \"relu\")\n        grads[\"dA\"+str(i)] = dA_prev_temp\n        grads[\"dW\"+str(i+1)] = dW_temp\n        grads[\"db\"+str(i+1)] = db_temp\n        \n    return grads","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.717046Z","iopub.execute_input":"2022-07-18T23:13:48.717399Z","iopub.status.idle":"2022-07-18T23:13:48.729181Z","shell.execute_reply.started":"2022-07-18T23:13:48.717366Z","shell.execute_reply":"2022-07-18T23:13:48.72839Z"},"trusted":true},"execution_count":831,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Descent\nLet's write a function to update the parameters of our model using gradient descent. We will use these two formulas: \n\n$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]}$$\n$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]}$$\n\nwhere $\\alpha$ is the learning rate of our model. \n","metadata":{}},{"cell_type":"code","source":"def update_parameters(params, grads, learning_rate):\n    \"\"\"\n    Implement gradient descent to update our parameters\n    Args:\n    params: dictionary containing parameters of our model\n    grads: dictionary containing our gradient vectors\n    Returns:\n    parameters: updated dictionary\n    \"\"\"\n    parameters = params.copy()\n    L = len(parameters)//2\n    \n    for i in range(L):\n        parameters[\"W\"+str(i+1)] = params[\"W\"+str(i+1)] - learning_rate*grads[\"dW\"+str(i+1)]\n        parameters[\"b\"+str(i+1)] = params[\"b\"+str(i+1)] - learning_rate*grads[\"db\"+str(i+1)]\n        \n    return parameters","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.778103Z","iopub.execute_input":"2022-07-18T23:13:48.778394Z","iopub.status.idle":"2022-07-18T23:13:48.784602Z","shell.execute_reply.started":"2022-07-18T23:13:48.778368Z","shell.execute_reply":"2022-07-18T23:13:48.78362Z"},"trusted":true},"execution_count":832,"outputs":[]},{"cell_type":"markdown","source":"We finally have all the functions necessary to implement a deep neural network.\n### Putting everything together\nLet's go ahead and make our label sets, and run a check on our matrix dimensions.","metadata":{}},{"cell_type":"code","source":"train_labels = np.array(train_df[\"Survived\"])\ntrain_labels = train_labels[np.newaxis]\ntrain_df = train_df.drop([\"Survived\"], axis=1)\ntrain_df.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.841826Z","iopub.execute_input":"2022-07-18T23:13:48.842595Z","iopub.status.idle":"2022-07-18T23:13:48.85163Z","shell.execute_reply.started":"2022-07-18T23:13:48.842555Z","shell.execute_reply":"2022-07-18T23:13:48.850705Z"},"trusted":true},"execution_count":833,"outputs":[{"execution_count":833,"output_type":"execute_result","data":{"text/plain":"(891, 7)"},"metadata":{}}]},{"cell_type":"markdown","source":"We have 7 input features, and 891 training sets.\nLet's initialize the parameters for our deep neural network. Let's choose to use 3 hidden layers, with 20, 7, and 5 nodes respectively in each layer. Of course, being a binary classifier, our neural network's output layer will be one node. \n\n\nWe will choose our learning rate to be .00075.\n\nFinally, for iterations, we will choose 500000 iterations of training.","metadata":{}},{"cell_type":"markdown","source":"To begin, let's convert our input data from a pandas dataframe to a Numpy array, and initialize our layer dimensions list","metadata":{}},{"cell_type":"code","source":"train_df = train_df.to_numpy().T\nlayer_dims = [7,20,7,5,1]","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:48.938399Z","iopub.execute_input":"2022-07-18T23:13:48.939024Z","iopub.status.idle":"2022-07-18T23:13:48.943449Z","shell.execute_reply.started":"2022-07-18T23:13:48.938987Z","shell.execute_reply":"2022-07-18T23:13:48.942425Z"},"trusted":true},"execution_count":834,"outputs":[]},{"cell_type":"markdown","source":"Let's create a function to facilitate our neural network.","metadata":{}},{"cell_type":"code","source":"def L_layer_nn(X, Y, layer_dims, learning_rate, num_iterations):\n    \"\"\"\n    Implements an L-Layer neural network with Linear->ReLU*(L-1) -> Linear->Sigmoid layers.\n    Args:\n    X: Input data -- np array\n    Y: Label vector\n    layer_dims: list containing our layer dimensions\n    num_iterations: number of iterations of the optimization loop\n    Returns:\n    parameters: the parameters learned by our model, which can be used to predict\n    \"\"\"\n    costs = []\n    parameters = {}\n    for i in range(1, len(layer_dims)):\n        parameters[\"W\"+str(i)] = np.random.randn(layer_dims[i], layer_dims[i-1])*np.sqrt(2/layer_dims[i-1])\n        parameters[\"b\"+str(i)] = np.zeros((layer_dims[i],1))\n    for i in range(0, num_iterations):\n        AL, caches = nn_forward(X, parameters)\n        cost = compute_cost(AL, Y)\n        grads = nn_backprop(AL, Y, caches)\n        parameters = update_parameters(parameters, grads, learning_rate)\n        if i % 100000 == 0 or i == num_iterations - 1:\n            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n        if (i % 100 == 0 or i == num_iterations) and cost < 1.0:\n            costs.append(cost)\n    return parameters, costs    ","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:49.038401Z","iopub.execute_input":"2022-07-18T23:13:49.039033Z","iopub.status.idle":"2022-07-18T23:13:49.049921Z","shell.execute_reply.started":"2022-07-18T23:13:49.038999Z","shell.execute_reply":"2022-07-18T23:13:49.048918Z"},"trusted":true},"execution_count":835,"outputs":[]},{"cell_type":"markdown","source":"Now that we have our neural network function written, let's train our model.","metadata":{}},{"cell_type":"code","source":"def plot_costs(costs, learning_rate):\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per hundreds)')\n    plt.title(\"Learning rate =\" + str(learning_rate))\n    plt.ylim(0,1)\n    plt.show()\n#winner - .00075, 86% accuracy\nlearning_rate = .00075\nparameters, costs = L_layer_nn(train_df, train_labels, layer_dims, learning_rate, num_iterations=500000)\nplot_costs(costs, learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:13:49.136006Z","iopub.execute_input":"2022-07-18T23:13:49.13659Z","iopub.status.idle":"2022-07-18T23:19:44.610065Z","shell.execute_reply.started":"2022-07-18T23:13:49.136556Z","shell.execute_reply":"2022-07-18T23:19:44.609185Z"},"trusted":true},"execution_count":836,"outputs":[{"name":"stdout","text":"Cost after iteration 0: 7.31256670288208\nCost after iteration 100000: 0.4198353762152607\nCost after iteration 200000: 0.3918104356237645\nCost after iteration 300000: 0.3799421656613495\nCost after iteration 400000: 0.3712028571222909\nCost after iteration 499999: 0.3636008662778901\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjB0lEQVR4nO3deZxddX3/8dd7ZpKZrJNMEiD7AmEJskeWAopAFaIFK2rButRSEX8/oJVWi9W68KgbtlX4/aj8qFqKVWRTCYoiKlSlBjIBEgkQCCF7QpaZLJPJJJnM5/fHOTecGe4kk+XOvTPn/Xw87mPO8j3nfr83N/d9z/ec872KCMzMLL+qyl0BMzMrLweBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPA+iRJ50paVO56mPUHDgLbb5KWSrqwnHWIiN9GxDHlrEOBpPMkreyl57pA0guSWiU9KmnyXspOScu0pttc2GX9xyWtlbRF0nck1fZkW0m3SWrJPHZI2ppZ/5iktsx6B3aFcxBYRZJUXe46AChREf9PJI0Gfgj8I9AANAJ372WTu4CngVHAp4H7JI1J9/U24AbgAmAyMA34Qk+2jYirI2Jo4ZGWvbfLc1+TKVMRgW17ERF++LFfD2ApcGGR5VUkHy4vAxuBe4CGzPp7gbXAZuA3wPGZdXcA3wQeArYBF6bP83fAgnSbu4G6tPx5wMoudSpaNl3/SWANsBr4KyCAo7pp32PAF4HHge3AUcCHgeeBrcAS4KNp2SFpmQ6gJX2M29drcYCv+1XA/2TmC899bJGyRwM7gGGZZb8Frk6nvw98KbPuAmBtT7bt8jxD0tfkzV1ev78q9/vUj54/KuKbjvUb1wLvBN5M8mHYDNyaWf8zYDpwGPAU8L0u27+P5AN4GPC7dNl7gYuAqcCJwF/s5fmLlpV0EXA9SbgcRRIi+/IBkg/eYcAyYB3wDmA4SSh8XdKpEbENuBhYHa99A17dg9diD0mTJG3ay+N9adHjgfmF7dLnfjld3tXxwJKI2JpZNj9TttO+0unDJY3qwbZZlwHrSYI968uSNkh6XNJ5xdptlaOm3BWwfuVqki6BlQCSPg8sl/SBiGiPiO8UCqbrmiXVR8TmdPEDEfF4Ot0mCeCW9IMVSQ8CJ+/l+bsr+17gPyJiYea5/3wfbbmjUD7108z0f0v6BXAuSaAVs9fXIlswIpYDI/ZRH4ChJB+6WZtJwqpY2c1Fyo7vZn1helgPts36EHBnRGQHLft74DlgJ3A58KCkkyPi5SLbWwXwEYEdSpOBHxW+yZJ0pewm+aZZLekrkl6WtIWkKwdgdGb7FUX2uTYz3UryIdWd7sqO67LvYs/TVacyki6WNEdSU9q2WXSue1fdvhY9eO7utJAckWQNJ+ma2d+yXdcXprf29HkkTSI5urozuzwinoiIrRGxIyL+k6SLbVbxJlklcBDYobQCuDgiRmQedRGxiqTb51KS7pl6YEq6jTLbl2oo3DXAhMz8xB5ss6cu6dU09wP/DBweESNIzmWoa9mMvb0WnaRdQy17eRSOXhYCJ2W2GwIcmS7vaiEwTVL2aOGkTNlO+0qnX42IjT3YtuADwOMRsaTI82cFnf+drcI4COxADZBUl3nUALcBXyxc0ihpjKRL0/LDSE5AbgQGA1/qxbreA3xY0nGSBpNcdbM/BgK1JN0y7ZIuBt6aWf8qMEpSfWbZ3l6LTiJieeb8QrFH4VzKj4A3SLpMUh3wWWBBRLxQZJ8vAs8An0v/ff6U5LzJ/WmRO4ErJc2QNAL4DMkJ+55sW/DBwjYFkkZIelvhPZGG2JuAnxdru1UGB4EdqIdIrlgpPD4P3AzMBn6RXlc+BzgjLX8nyUnXVST9x3N6q6IR8TPgFuBRYHHmuXf0cPutwHUkgdJMcnQzO7P+BZJLKJekXUHj2PtrcaDtWE9ycvaLaT3OIOmDB/Zc339bZpPLgZlp2a8A7073QUT8HLiJ5DVZTvJv87mebJs+11kkR1ldLxsdAPwTSWhuID1pnoaLVSh1Psdj1v9JOg54FqjteuLWLI98RGC5IOlPJdVKGgl8FXjQIWCWKFkQpLesr5P0bDfrJekWSYslLZB0aqnqYgZ8lORegJdJrt75WHmrY1Y5StY1JOlNJJeh3RkRbyiyfhZJ/+Eskr7OmyPioPpQzcxs/5XsiCAifgM07aXIpaQ3okTEHGCEpLGlqo+ZmRVXzjuLx9P5pp2V6bI1XQtKuorkdn+GDBly2rHHHtsrFTQz6y/mzZu3ISLGFFvXJ4aYiIjbgdsBZs6cGY2NjWWukZlZ3yJpWXfrynnV0Co63+E5IV1mZma9qJxBMBv4YHr10JnA5oh4XbeQmZmVVsm6hiTdRTIg1Wglv970OZK7DomI20juTJ1FcqdnK8nQvmZm1stKFgQRccU+1gfwv0v1/GZm1jO+s9jMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzy7mSBoGkiyQtkrRY0g1F1k+S9KikpyUtkDSrlPUxM7PXK1kQSKoGbgUuBmYAV0ia0aXYZ4B7IuIU4HLg30pVHzMzK66URwSnA4sjYklE7AR+AFzapUwAw9PpemB1CetjZmZFlDIIxgMrMvMr02VZnwfeL2kl8BBwbbEdSbpKUqOkxvXr15eirmZmuVXuk8VXAHdExARgFvBdSa+rU0TcHhEzI2LmmDFjer2SZmb9WSmDYBUwMTM/IV2WdSVwD0BE/B6oA0aXsE5mZtZFKYNgLjBd0lRJA0lOBs/uUmY5cAGApONIgsB9P2ZmvahkQRAR7cA1wMPA8yRXBy2UdKOkS9Jifwt8RNJ84C7gLyIiSlGfxqVNfP2RF9m1u6MUuzcz67NqSrnziHiI5CRwdtlnM9PPAWeXsg4FjcuauflXL/HRN09jQHW5T42YmVWO3HwiVin5W5rjDTOzvis3QSCSJOhwEpiZdZKfICgcEZS3GmZmFSdHQZAkgQ8IzMw6y08QpH9LdFGSmVmflZ8g8MliM7OichMEVYWuoTLXw8ys0uQmCApHBL5qyMyss/wEQfrXOWBm1ll+gmBP15CTwMwsK0dBkPz1EYGZWWf5CQJ8H4GZWTG5CYI9Yw25a8jMrJPcBMFrVw2Vtx5mZpUmP0Gwp2vISWBmlpWbIMAni83MispNEFR50Dkzs6JyEwR7bijzyWIzs07yEwTuGjIzKyo3QeBB58zMistNEHjQOTOz4nITBAXOATOzznITBK9dNeQkMDPLyk0QNAwZCMD6lh1lromZWWXJTRBMHDkYgJVN28tcEzOzypKbIBg7oo4qwYrm1nJXxcysouQmCAZUVzG2fhDLmxwEZmZZuQkCgEkNg1nhIDAz6yRXQTCxYRArmn2OwMwsK19BMHIw67fuoG3X7nJXxcysYuQrCBqSK4fcPWRm9ppcBcGxY4cB8IdVm8tcEzOzypGrIJh+2DCG1tbw1PLmclfFzKxi5CoIqqvEKZNGMG/ZpnJXxcysYpQ0CCRdJGmRpMWSbuimzHslPSdpoaTvl7I+AKdNHsmitVto3raz1E9lZtYnlCwIJFUDtwIXAzOAKyTN6FJmOvAp4OyIOB74m1LVp+C8Yw6jI+CxF9eV+qnMzPqEUh4RnA4sjoglEbET+AFwaZcyHwFujYhmgIgo+afziePrGT20ll897yAwM4PSBsF4YEVmfmW6LOto4GhJj0uaI+miYjuSdJWkRkmN69evP6hKVVWJC449jMcWrWf7Tt9PYGZW7pPFNcB04DzgCuDfJY3oWigibo+ImRExc8yYMQf9pO88ZTwtO9r5+cI1B70vM7O+rpRBsAqYmJmfkC7LWgnMjohdEfEK8CJJMJTUGVMbmNQwmLvnrth3YTOzfq6UQTAXmC5pqqSBwOXA7C5lfkxyNICk0SRdRUtKWCcg6R66/PSJzFnSxLO+uczMcq5kQRAR7cA1wMPA88A9EbFQ0o2SLkmLPQxslPQc8CjwiYjYWKo6Zb3/zMkMr6vhll+91BtPZ2ZWsWpKufOIeAh4qMuyz2amA7g+ffSq4XUD+MtzpvKNX77E3KVNvHFKQ29XwcysIpT7ZHFZfeTcaUxsGMQn7p1P6872clfHzKwsch0EQ2pruOmyk1jW1MrnHlhY7uqYmZVFroMA4KwjR3HtW47i3nkr+eFTK8tdHTOzXpf7IAC47oLpnD61gc/8+FkWr2spd3XMzHqVgwCoqa7ilstPoaZK3OyriMwsZxwEqSPq63jT0WOYt7Sp3FUxM+tVDoKMUyeNZPXmNtZubit3VczMeo2DIOPUySMB/AtmZpYrPQoCSe/pybK+bsbY4dTWVPHUMgeBmeVHT48IPtXDZX3awJoqTpxQzzwfEZhZjux1iAlJFwOzgPGSbsmsGg70y1txT5vcwLd/t4TWne0MHljSETjMzCrCvo4IVgONQBswL/OYDbyttFUrj7OOHMWu3UHjUh8VmFk+7PUrb0TMB+ZL+n5E7AKQNBKYWPh5yf7mjVNGUlMlHn95A286+uB/BMfMrNL19BzBI5KGS2oAniL5JbGvl7BeZTN4YA3nTh/N/fNWsaPdP2VpZv1fT4OgPiK2AO8C7oyIM4ALSlet8rrynGlsaNnhXzAzs1zoaRDUSBoLvBf4SQnrUxHOPmoUZ05r4Bu/fIktbbvKXR0zs5LqaRDcSPJrYi9HxFxJ04B+OyiPJD49awZN23byfzz2kJn1cz0Kgoi4NyJOjIiPpfNLIuKy0latvE6YUM8Vp0/iW797hbkef8jM+rGe3lk8QdKPJK1LH/dLmlDqypXbZ95+HBNHDub6e55hq7uIzKyf6mnX0H+Q3DswLn08mC7r14bU1vCv7z2J1ZvauO6up9ndEeWukpnZIdfTIBgTEf8REe3p4w4gFxfZz5zSwBcuOZ5HF63n7+9f4DAws36np2MobJT0fuCudP4KYGNpqlR53n/mZDa27OTrv3yRlrZ2bnrPiQyvG1DuapmZHRI9PSL4S5JLR9cCa4B3A39RojpVpL++cDr/+I4ZPPL8q7zjlt8xb5lPIJtZ/7A/l49+KCLGRMRhJMHwhdJVqzJdec5U7r7qTNp3d3DZN3/PtXc9zfKNreWulpnZQelpEJyYHVsoIpqAU0pTpco2c0oDj1z/Zq47/ygeeW4t5//LY9xw/wJWNDkQzKxv6mkQVKWDzQGQjjmU2zGah9TWcP1bj+G/P/EW3n/mZH749Cre8s+P8cn75vPSq1vLXT0zs/2iiH1fBSPpg8A/APemi94DfDEivlvCuhU1c+bMaGxs7O2n3au1m9v45mOLubtxBW27Ojh9SgN/cvI4Zr3hCEYNrS139czMkDQvImYWXdeTIEh3MgM4P539dUQ8d4jqt18qMQgKmrbt5PtPLOPHz6xm8boWqqvEHx05iovecARnTB3FkWOGIKnc1TSzHDokQVApKjkICiKCRa9u5cH5q3lw/hqWp+cPRg4ewGmTRzJzSgMzJ4/khAn11NZUl7m2ZpYHDoIyigiWbNjGvKXNzF3axLxlzSzZsA2AgdXJbySfPHEERx42lKmjhzBtzBDGDK31kYOZHVJ7C4LcnvDtLZI4csxQjhwzlPe+cSIAG1t2MG9ZM43Lmmlc2sR35yxjR3vHnm2G1dYwdcwQpo0ewrQxrwXE1NFD/DvKZnbI+YigAnR0BKs3b2fJ+m0sWd/CKxu2sWTDNpas38bqzdvJ/hONra/bEwzTRichMXnUYCY2DGZAdU8vAjOzvPERQYWrqhITRg5mwsjBr/ud5LZdu3llw7YkHNa3JGGxYRuzn1nNlrb2PeWqq8SEkYOY1DCYKaOGMH7kICaOHLwnJIbX1bi7ycyKchBUuLoB1Rw3djjHjR3eaXlEsHHbTpZtTI4clm7cxrKNrSxvauWBZ1Z1CgmAobU1jB8xiCPq6xhbX8fY+kGMra/bM39EfR3DPH6SWS45CPooSYweWsvoobWcNrnhdeu3tO1iRVMrSze0snrTdlZt2s7yplbWb93BwtWb2dCy83XbDK2t4fDhtdQPGsDQugFMbhjMyCEDmTJqMCMGD0AoOZk9rJa6mmqqqnyEYdYflDQIJF0E3AxUA9+KiK90U+4y4D7gjRHRv04AlMnwugEcP66e48fVF12/o30367bsYM3mNtZs3s6rW9qS6U1tbN2xi1XNrcxfsYnN2w/8B3luvPR4jj1iONt37Wb8iDoahiQhUyXcTWVWQUoWBJKqgVuBPwZWAnMlze56I5qkYcBfA0+Uqi72erU11UxsSM4f7E3brt2s3rSd59dsZe2WNuYta6Kuppr1LTv4/csbGT9yEMu6GXjvsw8s7Ha/hw+vpbames89Fl3NOuEIjjl8OFefN833WpiVWMmuGpJ0FvD5iHhbOv8pgIj4cpdy3wAeAT4B/N2+jgj641VD/UVEsHhdC6s2befJV5o4bfJImlt38c3HFvPy+m2dyv7ZzInsaN/Nj59Zvc/9fubtx/Hln73AtecfxcLVW7js1AlceNxhVFfJRxZmPVSWG8okvRu4KCL+Kp3/AHBGRFyTKXMq8OmIuEzSY3QTBJKuAq4CmDRp0mnLli0rSZ2t/Arvxx3tHXzhwYXc9eSK/d7HO04cy2WnTeDkCSOSriifyzCrzMtHJVUB/0oPfuAmIm4HbofkiKC0NbNyKnzDrxtQzZffdSJf+tMT2NCyk3nLmtnatotP3Ldgn/v4yYI1/GTBmm7XnzG1gTOnjWLZxm2MHlrL4vUtHHPEMP7oyNGMS6+gGjKwhrVb2tja1s7wQTUMHljD0Noaqh0q1g+VrWtIUj3wMtCSbnIE0ARcsrfuIXcNWTHN23by9Ipmfv3COv5rznLOmjaKw4bX8kAPup7KaeroIRx9+FDOmT6GqaOGMHrYQCKSK7jaO4KGIQOpG1DFwOqqTt1g23a0M7CmigiQ8M2Etk/l6hqqAV4ELgBWAXOB90VE0TOIe+saynIQ2MEovN+bW3fx7KrNrN3cxq9fWMeO9t3UDxrA7xZv2PMBvKTLeY3+pLpK7O7o/H9/1JCBjB1RxwnjR3DC+HqeXt7M208cy9DaGjoCVm1q5eyjRjO8bgArm7dTW1PF4cPrGFhTxc72DmqqRHtH0N7R4aFQKlDZBp2TNAv4Bsnlo9+JiC9KuhFojIjZXco+hoPA+pDCFVXjRgxiQ8sOWna0Uy2xefsuRg+tZc3mNnZ3BBLMXdrEN375UrmrXNFmjB3Oc2u27Jm/4vRJ3PXk8j3zJ08cwfHjkjLnH3MY23buZkVTK5NHDWZnewcXzjicI8cMZXdH0BHB7o5gxOABDKiu4olXmhg/oo5po4ciwcrm7YwaOpDammo2te6kpqqK2gFV1NZU9dsLEDz6qFk/0b67g5pMN9DujuQD7+7GFazetJ2jDx/KSRNGsGxjK7f8+iXGjRjEmVMbuOnhRWztcre5HRrHjxvOwtWvBdhJE+r55EXHcvZRo4FkLLHfLd7A1NFD6Ihg8qghRASS9vwt6OgI2juCgTWHvqvPQWBmZdG0bSePL97A6VMbaFzazO4Irrvr6XJXq8/6/afOZ2z9oAPa1kFgZhWpcJ5CwK6ODtp3BzvbOxhcW31ANxIWvlGvbG6ladtOTp00ki1tu9i8fRcDa6pYv3UHdQOqmbNkIy++upWB1dWMGjqQhxeupaWtfc9vhVSqa88/ir996zEHtK2DwMysQkQEhfP0y5taWbu5jZpq8dMFa9i1u4PdHcFL61oYOXggT76ykfaO4IypDZwxbRQfOXfaAV/CXJH3EZiZ5ZEkqtPP8qmjkx+cAnjjlNcPHtlbfPGxmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznShoEki6StEjSYkk3FFl/vaTnJC2Q9CtJk0tZHzMze72SBYGkauBW4GJgBnCFpBldij0NzIyIE4H7gJtKVR8zMyuulEcEpwOLI2JJROwEfgBcmi0QEY9GRGs6OweYUML6mJlZEaUMgvHAisz8ynRZd64EflZshaSrJDVKaly/fv0hrKKZmVXEyWJJ7wdmAl8rtj4ibo+ImRExc8yYMb1bOTOzfq6mhPteBUzMzE9Il3Ui6ULg08CbI2JHCetjZmZFlPKIYC4wXdJUSQOBy4HZ2QKSTgH+H3BJRKwrYV3MzKwbJQuCiGgHrgEeBp4H7omIhZJulHRJWuxrwFDgXknPSJrdze7MzKxEStk1REQ8BDzUZdlnM9MXlvL5zcxs3yriZLGZmZWPg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjlX0iCQdJGkRZIWS7qhyPpaSXen65+QNKWU9TEzs9crWRBIqgZuBS4GZgBXSJrRpdiVQHNEHAV8HfhqqepjZmbFlfKI4HRgcUQsiYidwA+AS7uUuRT4z3T6PuACSSphnczMrIuaEu57PLAiM78SOKO7MhHRLmkzMArYkC0k6SrgqnS2RdKiA6zT6K77zgG3OR/c5nw4mDZP7m5FKYPgkImI24HbD3Y/khojYuYhqFKf4Tbng9ucD6Vqcym7hlYBEzPzE9JlRctIqgHqgY0lrJOZmXVRyiCYC0yXNFXSQOByYHaXMrOBD6XT7wZ+HRFRwjqZmVkXJesaSvv8rwEeBqqB70TEQkk3Ao0RMRv4NvBdSYuBJpKwKKWD7l7qg9zmfHCb86EkbZa/gJuZ5ZvvLDYzyzkHgZlZzuUmCPY13EVfIuk7ktZJejazrEHSI5JeSv+OTJdL0i1puxdIOjWzzYfS8i9J+lCx56oEkiZKelTSc5IWSvrrdHl/bnOdpCclzU/b/IV0+dR0OJbF6fAsA9Pl3Q7XIulT6fJFkt5Wpib1mKRqSU9L+kk636/bLGmppD9IekZSY7qsd9/bEdHvHyQnq18GpgEDgfnAjHLX6yDa8ybgVODZzLKbgBvS6RuAr6bTs4CfAQLOBJ5IlzcAS9K/I9PpkeVuWzftHQucmk4PA14kGbakP7dZwNB0egDwRNqWe4DL0+W3AR9Lp/8XcFs6fTlwdzo9I32/1wJT0/8H1eVu3z7afj3wfeAn6Xy/bjOwFBjdZVmvvrfzckTQk+Eu+oyI+A3JVVZZ2eE6/hN4Z2b5nZGYA4yQNBZ4G/BIRDRFRDPwCHBRySt/ACJiTUQ8lU5vBZ4nuSu9P7c5IqIlnR2QPgI4n2Q4Fnh9m4sN13Ip8IOI2BERrwCLSf4/VCRJE4C3A99K50U/b3M3evW9nZcgKDbcxfgy1aVUDo+INen0WuDwdLq7tvfJ1yQ9/D+F5Btyv25z2kXyDLCO5D/2y8CmiGhPi2Tr32m4FqAwXEufajPwDeCTQEc6P4r+3+YAfiFpnpLhdKCX39t9YogJ2z8REZL63XXBkoYC9wN/ExFblBmfsD+2OSJ2AydLGgH8CDi2vDUqLUnvANZFxDxJ55W5Or3pnIhYJekw4BFJL2RX9sZ7Oy9HBD0Z7qKvezU9RCT9uy5d3l3b+9RrImkASQh8LyJ+mC7u120uiIhNwKPAWSRdAYUvcNn6dzdcS19q89nAJZKWknTfng/cTP9uMxGxKv27jiTwT6eX39t5CYKeDHfR12WH6/gQ8EBm+QfTqw3OBDanh5wPA2+VNDK9IuGt6bKKk/b7fht4PiL+NbOqP7d5THokgKRBwB+TnBt5lGQ4Fnh9m4sN1zIbuDy9wmYqMB14slcasZ8i4lMRMSEippD8H/11RPw5/bjNkoZIGlaYJnlPPktvv7fLfca8tx4kZ9tfJOln/XS563OQbbkLWAPsIukLvJKkb/RXwEvAL4GGtKxIfiDoZeAPwMzMfv6S5ETaYuDD5W7XXtp7Dkk/6gLgmfQxq5+3+UTg6bTNzwKfTZdPI/lQWwzcC9Smy+vS+cXp+mmZfX06fS0WAReXu209bP95vHbVUL9tc9q2+eljYeGzqbff2x5iwsws5/LSNWRmZt1wEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GVhKT/Sf9OkfS+Q7zvfyj2XKUi6Z2SPluifbfsu9QB7fe8wuidB7GPpZJG72X9DyRNP5jnsMrgILCSiIg/SienAPsVBJm7SLvTKQgyz1UqnwT+7WB30oN2ldwhrsM3SV4b6+McBFYSmW+6XwHOTcda/3g6kNrXJM1Nx1P/aFr+PEm/lTQbeC5d9uN0IK6FhcG4JH0FGJTu73vZ50rvtvyapGeVjO/+Z5l9PybpPkkvSPpeercykr6i5HcOFkj65yLtOBrYEREb0vk7JN0mqVHSi+n4OIUB4nrUriLP8UUlvzswR9Lhmed5d6ZMS2Z/3bXlonTZU8C7Mtt+XtJ3JT1O8hvhYyTdn9Z1rqSz03KjJP0ifb2/RXLzUuHu15+mdXy28LoCvwUurISAs4NU7jvr/OifD6Al/Xse6R2i6fxVwGfS6VqgkWTM+POAbcDUTNnC3ZSDSO6uHZXdd5HnuoxklM5qktEal5P8lsF5JCNTTiD58vN7kruVR5HceVq4sXJEkXZ8GPiXzPwdwM/T/UwnubO7bn/a1WX/AfxJOn1TZh93AO/u5vUs1pY6ktEnp5N8gN/Da3fmfh6YBwxK579PMtAZwCSSoTsAbuG1O5jfntZtdPq6/numLvWZ6UeA08r9fvPj4B4+IrDe9laSsVKeIRlKehTJhxfAk5GMH19wnaT5wBySAbX21R99DnBXROyOiFeB/wbemNn3yojoIBmiYgrJB2ob8G1J7wJai+xzLLC+y7J7IqIjIl4i+QGQY/ezXVk7gUJf/ry0XvtSrC3HAq9ExEuRfEL/V5dtZkfE9nT6QuD/pnWdDQxXMrLrmwrbRcRPgea0/B+AP5b0VUnnRsTmzH7XAeN6UGerYD6ks94m4NqI6DQglpJhh7d1mb8QOCsiWiU9RvKt90DtyEzvBmoiol3S6cAFJIOWXUMy4mXWdpJRLbO6jssS9LBdRexKP7j31CudbiftupVURfLLet22ZS/7L8jWoQo4MyLautS16IYR8aKSn0ScBfyTpF9FxI3p6jqS18j6MB8RWKltJfl5yYKHgY8pGVYaSUcrGXWxq3qgOQ2BY0l+lq9gV2H7Ln4L/FnaXz+G5Btut6NOpt+C6yPiIeDjwElFij0PHNVl2XskVUk6kmTQsEX70a6eWgqclk5fQvILZXvzAjAlrRPAFXsp+wvg2sKMpJPTyd+QntiXdDHJTx4iaRzQGhH/BXyN5GdSC44m6bazPsxHBFZqC4DdaRfPHSTjy08BnkpPcq7ntZ/hy/o5cLWk50k+aOdk1t0OLJD0VCTDFBf8iGTM/vkk39I/GRFr0yApZhjwgKQ6km/01xcp8xvgXyQp8819OUnADAeujoi29ORqT9rVU/+e1m0+yWuxt6MK0jpcBfxUUitJKA7rpvh1wK2SFpB8BvwGuBr4AnCXpIXA/6TtBDgB+JqkDpIRbz8GkJ7Y3h4Raw+8mVYJPPqo2T5Iuhl4MCJ+KekOkpOw9+1js35P0seBLRHx7XLXxQ6Ou4bM9u1LwOByV6ICbeK1H1i3PsxHBGZmOecjAjOznHMQmJnlnIPAzCznHARmZjnnIDAzy7n/D67ZIekIyjwWAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"Let's write a quick prediction function to see how our model is performing.","metadata":{}},{"cell_type":"code","source":"def predict(X, Y, parameters):\n    \"\"\"\n    Predicts results of a L-layer neural network.\n    Args:\n    X: data set of examples being predicted\n    Y: true labels\n    parameters: parameters of the trained model\n    Returns:\n    predictions: predictions of the given dataset X\n    \"\"\"\n    m = X.shape[1]\n    n = len(parameters) // 2\n    p = np.zeros((1,m))\n    \n    probas, caches = nn_forward(X, parameters)\n    for i in range(0, probas.shape[1]):\n        if probas[0, i] > 0.5:\n            p[0, i] = 1\n        else:\n            p[0, i] = 0\n    print(\"Accuracy: \"+str(np.sum((p == Y) / m)))\n    \n    return p","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:19:44.611576Z","iopub.execute_input":"2022-07-18T23:19:44.612005Z","iopub.status.idle":"2022-07-18T23:19:44.618958Z","shell.execute_reply.started":"2022-07-18T23:19:44.61196Z","shell.execute_reply":"2022-07-18T23:19:44.617821Z"},"trusted":true},"execution_count":837,"outputs":[]},{"cell_type":"code","source":"pred_train = predict(train_df, train_labels, parameters)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:19:44.620072Z","iopub.execute_input":"2022-07-18T23:19:44.620953Z","iopub.status.idle":"2022-07-18T23:19:44.635204Z","shell.execute_reply.started":"2022-07-18T23:19:44.620916Z","shell.execute_reply":"2022-07-18T23:19:44.634409Z"},"trusted":true},"execution_count":838,"outputs":[{"name":"stdout","text":"Accuracy: 0.8496071829405163\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Nice. Let's wrap things up by predicting the survivorship of our test set.","metadata":{}},{"cell_type":"code","source":"pass_ids = test_df[\"PassengerId\"]\ntest_df = np.array(test_df.drop([\"PassengerId\"], axis=1)).T\nprobas, caches = nn_forward(test_df, parameters)\np = np.zeros((1, test_df.shape[1]))\nfor i in range(0, probas.shape[1]):\n    if probas[0, i] > 0.5:\n        p[0, i] = 1\n    else:\n        p[0, i] = 0\np = np.resize(p, (p.shape[1],))","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:19:44.636908Z","iopub.execute_input":"2022-07-18T23:19:44.637673Z","iopub.status.idle":"2022-07-18T23:19:44.648552Z","shell.execute_reply.started":"2022-07-18T23:19:44.637623Z","shell.execute_reply":"2022-07-18T23:19:44.647639Z"},"trusted":true},"execution_count":839,"outputs":[]},{"cell_type":"markdown","source":"And let's finally submit our findings.","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": pass_ids,\n        \"Survived\": p.astype('int')})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T23:43:25.657076Z","iopub.execute_input":"2022-07-18T23:43:25.657428Z","iopub.status.idle":"2022-07-18T23:43:25.666784Z","shell.execute_reply.started":"2022-07-18T23:43:25.657399Z","shell.execute_reply":"2022-07-18T23:43:25.665811Z"},"trusted":true},"execution_count":843,"outputs":[]},{"cell_type":"markdown","source":"### Results\nThis notebook was my personal endeavour for understanding more comprehensively the workings of a neural network. I played around a lot with the hyperparameters, to no avail. I fiddled around with my math, and had to debug many errors such as division by zero due to floating point accuracy, or my code generally not behaving as expected. But I had a lot of fun with this notebook. \n\n#### Inspirations and sources\nOf course, this neural network model is inspired by [Andrew Ng's Coursera Course on Deep Learning and Neural Networks](https://www.coursera.org/learn/neural-networks-deep-learning).\n\nAs for feature engineering, I deferred to [Mr. Manav Sehgal's notebook on this data set](https://www.kaggle.com/code/startupsci/titanic-data-science-solutions/notebook), which provided much needed guidance throughout this journey.\n\n**-- Thank you for reading my notebook --**","metadata":{}}]}